{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "Jw3kEEiJ1Alg",
        "outputId": "cf689c2e-c41f-44be-de18-d5246ffb0af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID3 Decision Tree for loan.csv:\n",
            "Attribute/Leaf: Age\n",
            "Children:\n",
            "  Decision: Senior\n",
            "  Attribute/Leaf: Income_Level\n",
            "  Children:\n",
            "    Decision: Low\n",
            "    Attribute/Leaf: No\n",
            "    Decision: Medium\n",
            "    Attribute/Leaf: Yes\n",
            "    Decision: High\n",
            "    Attribute/Leaf: Yes\n",
            "  Decision: Young\n",
            "  Attribute/Leaf: Job_Type\n",
            "  Children:\n",
            "    Decision: Salaried\n",
            "    Attribute/Leaf: Income_Level\n",
            "    Children:\n",
            "      Decision: Low\n",
            "      Attribute/Leaf: No\n",
            "      Decision: High\n",
            "      Attribute/Leaf: Yes\n",
            "    Decision: Self_Employed\n",
            "    Attribute/Leaf: Yes\n",
            "    Decision: UnEmployed\n",
            "    Attribute/Leaf: Yes\n",
            "  Decision: Middle_Aged\n",
            "  Attribute/Leaf: No\n",
            "\n",
            "Random Forest Classifier Results:\n",
            "Accuracy: 0.6666666666666666\n",
            "\n",
            "Confusion Matrix:\n",
            "[[0 1]\n",
            " [0 2]]\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00         1\\n           1       0.67      1.00      0.80         2\\n\\n    accuracy                           0.67         3\\n   macro avg       0.33      0.50      0.40         3\\nweighted avg       0.44      0.67      0.53         3\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "dataset = pd.read_csv('loan.csv')\n",
        "\n",
        "\n",
        "original_data = dataset.values.tolist()\n",
        "\n",
        "attributes = dataset.columns[:-1].tolist()\n",
        "target_attribute = dataset.columns[-1]\n",
        "\n",
        "class Node(object):\n",
        "    def __init__(self):\n",
        "        self.value = None\n",
        "        self.decision = None\n",
        "        self.childs = None\n",
        "\n",
        "\n",
        "def entropy(data):\n",
        "    target_values = [row[-1] for row in data]\n",
        "    value_counts = pd.Series(target_values).value_counts()\n",
        "    total_count = len(target_values)\n",
        "    entropy_value = 0\n",
        "    for count in value_counts:\n",
        "        probability = count / total_count\n",
        "        entropy_value -= probability * math.log2(probability)\n",
        "    return entropy_value\n",
        "\n",
        "\n",
        "def information_gain(data, attribute_index):\n",
        "    total_entropy = entropy(data)\n",
        "    attribute_values = [row[attribute_index] for row in data]\n",
        "    value_counts = pd.Series(attribute_values).value_counts()\n",
        "    total_count = len(attribute_values)\n",
        "    weighted_entropy = 0\n",
        "    for value, count in value_counts.items():\n",
        "        subset = [row for row in data if row[attribute_index] == value]\n",
        "        weighted_entropy += (count / total_count) * entropy(subset)\n",
        "    return total_entropy - weighted_entropy\n",
        "\n",
        "\n",
        "def build_tree(data, available_attributes):\n",
        "    target_values = [row[-1] for row in data]\n",
        "\n",
        "\n",
        "    if len(set(target_values)) == 1:\n",
        "        root = Node()\n",
        "        root.value = target_values[0]\n",
        "        return root\n",
        "\n",
        "\n",
        "    if not available_attributes:\n",
        "        root = Node()\n",
        "\n",
        "        root.value = pd.Series(target_values).mode()[0]\n",
        "        return root\n",
        "\n",
        "\n",
        "    best_attribute_index = -1\n",
        "    max_gain = -1\n",
        "    original_attribute_indices = [dataset.columns.get_loc(attr) for attr in attributes]\n",
        "\n",
        "    for attr_name in available_attributes:\n",
        "        attr_index_in_original_data = dataset.columns.get_loc(attr_name)\n",
        "        gain = information_gain(data, attr_index_in_original_data)\n",
        "        if gain > max_gain:\n",
        "            max_gain = gain\n",
        "            best_attribute_index = attr_index_in_original_data\n",
        "\n",
        "    if max_gain == 0:\n",
        "        root = Node()\n",
        "        root.value = pd.Series(target_values).mode()[0]\n",
        "        return root\n",
        "\n",
        "\n",
        "    best_attribute_name = dataset.columns[best_attribute_index]\n",
        "\n",
        "    root = Node()\n",
        "    root.value = best_attribute_name\n",
        "    root.childs = []\n",
        "\n",
        "    attribute_values = [row[best_attribute_index] for row in data]\n",
        "    unique_values = set(attribute_values)\n",
        "\n",
        "    remaining_attributes = [attr for attr in available_attributes if attr != best_attribute_name]\n",
        "\n",
        "    for value in unique_values:\n",
        "        subset = [row for row in data if row[best_attribute_index] == value]\n",
        "        if not subset:\n",
        "             continue\n",
        "        child_node = build_tree(subset, remaining_attributes)\n",
        "        child_node.decision = value\n",
        "        root.childs.append(child_node)\n",
        "\n",
        "    return root\n",
        "\n",
        "def print_tree(node, indent=\"\"):\n",
        "    if node.decision is not None:\n",
        "        print(f\"{indent}Decision: {node.decision}\")\n",
        "\n",
        "    print(f\"{indent}Attribute/Leaf: {node.value}\")\n",
        "\n",
        "    if node.childs:\n",
        "        print(f\"{indent}Children:\")\n",
        "        for child in node.childs:\n",
        "            print_tree(child, indent + \"  \")\n",
        "\n",
        "\n",
        "\n",
        "id3_tree_root = build_tree(original_data, attributes)\n",
        "print(\"ID3 Decision Tree for loan.csv:\")\n",
        "print_tree(id3_tree_root)\n",
        "\n",
        "categorical_cols = ['Age', 'Job_Type', 'Income_Level', 'Credit_History','Loan_Amount']\n",
        "target_col = dataset.columns[-1]\n",
        "\n",
        "\n",
        "for col in categorical_cols:\n",
        "  le = LabelEncoder()\n",
        "  dataset[col] = le.fit_transform(dataset[col])\n",
        "\n",
        "le_target = LabelEncoder()\n",
        "dataset[target_col] = le_target.fit_transform(dataset[target_col])\n",
        "\n",
        "X = dataset[categorical_cols]\n",
        "y = dataset[target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nRandom Forest Classifier Results:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "class_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "\n",
        "cart_classifier = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "\n",
        "cart_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred_cart = cart_classifier.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy_cart = accuracy_score(y_test, y_pred_cart)\n",
        "conf_matrix_cart = confusion_matrix(y_test, y_pred_cart)\n",
        "class_report_cart = classification_report(y_test, y_pred_cart)\n",
        "\n",
        "print(f\"\\nCART Classifier Results:\")\n",
        "print(f\"Accuracy: {accuracy_cart}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix_cart)\n",
        "print(\"\\nClassification Report:\")\n",
        "class_report_cart\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "oEFig-jFDFF3",
        "outputId": "e7730ae1-d999-4bad-d309-4345f05db3e1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CART Classifier Results:\n",
            "Accuracy: 1.0\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0]\n",
            " [0 2]]\n",
            "\n",
            "Classification Report:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'              precision    recall  f1-score   support\\n\\n           0       1.00      1.00      1.00         1\\n           1       1.00      1.00      1.00         2\\n\\n    accuracy                           1.00         3\\n   macro avg       1.00      1.00      1.00         3\\nweighted avg       1.00      1.00      1.00         3\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def predict(tree, row, attributes):\n",
        "    if tree.childs is None:\n",
        "        return tree.value\n",
        "\n",
        "    attribute_index = attributes.index(tree.value)\n",
        "    attribute_value = row[attribute_index]\n",
        "\n",
        "    for child in tree.childs:\n",
        "        if child.decision == attribute_value:\n",
        "            return predict(child, row, attributes)\n",
        "\n",
        "\n",
        "    if tree.childs:\n",
        "        return tree.childs[0].value\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def evaluate_id3(tree, data, attributes):\n",
        "    true_labels = [row[-1] for row in data]\n",
        "    predicted_labels = []\n",
        "    unique_labels = sorted(list(set(true_labels)))\n",
        "    label_to_index = {label: i for i, label in enumerate(unique_labels)}\n",
        "\n",
        "    for row in data:\n",
        "\n",
        "        prediction_row = row[:-1]\n",
        "        predicted_labels.append(predict(tree, prediction_row, attributes))\n",
        "\n",
        "\n",
        "    all_labels = sorted(list(set(true_labels + predicted_labels)))\n",
        "    all_label_to_index = {label: i for i, label in enumerate(all_labels)}\n",
        "\n",
        "\n",
        "    correct_predictions = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred])\n",
        "    accuracy = correct_predictions / len(true_labels) if len(true_labels) > 0 else 0\n",
        "\n",
        "    n_classes = len(all_labels)\n",
        "    conf_matrix = [[0] * n_classes for _ in range(n_classes)]\n",
        "\n",
        "    for true, pred in zip(true_labels, predicted_labels):\n",
        "        true_index = all_label_to_index.get(true, -1)\n",
        "        pred_index = all_label_to_index.get(pred, -1)\n",
        "\n",
        "        if true_index != -1 and pred_index != -1:\n",
        "            conf_matrix[true_index][pred_index] += 1\n",
        "\n",
        "\n",
        "    return accuracy, conf_matrix, all_labels\n",
        "\n",
        "\n",
        "accuracy_id3, conf_matrix_id3, labels_id3 = evaluate_id3(id3_tree_root, original_data, attributes)\n",
        "\n",
        "print(f\"\\nID3 Classifier Results:\")\n",
        "print(f\"Accuracy: {accuracy_id3}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(\"Labels:\", labels_id3)\n",
        "for row in conf_matrix_id3:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMYVgx75F0lV",
        "outputId": "d241cd89-289d-4c54-85bc-1463a6061f30"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ID3 Classifier Results:\n",
            "Accuracy: 1.0\n",
            "\n",
            "Confusion Matrix:\n",
            "Labels: ['No', 'Yes']\n",
            "[5, 0]\n",
            "[0, 9]\n"
          ]
        }
      ]
    }
  ]
}